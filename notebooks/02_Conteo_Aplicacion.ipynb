{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db8020c9",
   "metadata": {},
   "source": [
    "# Bloque 1: Importaciones y Configuración\n",
    "\n",
    "- Propósito: Cargar las librerías necesarias (numpy, librosa, joblib, os).\n",
    "También definimos las variables clave:\n",
    "1) MODELO_PATH: Dónde está guardado nuestro modelo entrenado.\n",
    "2) AUDIO_PARA_CLASIFICAR: El nombre del archivo de audio que queremos probar.\n",
    "3) CLASES_MAP: Un \"diccionario\" para traducir la predicción numérica (0, 1, 2) a texto.\n",
    "4) N_MFCC: El número de características que usamos (debe ser el mismo del entrenamiento)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6b95a361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaciones\n",
    "import numpy as np\n",
    "import librosa\n",
    "import joblib\n",
    "import os \n",
    "MODELO_PATH = \"clasificador_vehiculos.joblib\"\n",
    "AUDIO_PARA_CLASIFICAR = \"audio_random.wav\" \n",
    "\n",
    "# Mapeo de las etiquetas numéricas a texto\n",
    "CLASES_MAP = {0: \"pequeno\", 1: \"mediano\", 2: \"grande\"} \n",
    "N_MFCC = 40 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c24bae",
   "metadata": {},
   "source": [
    "# Bloque 2: Función de Extracción de Características\n",
    "\n",
    "- Propósito: Definir la función que convierte un archivo de audio en números.\n",
    "Esta función DEBE ser una copia exacta de la que se usó en el notebook 1.\n",
    "Carga el audio, calcula los 40 MFCCs, y luego calcula la media de esos MFCCs\n",
    "para obtener un solo vector de características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "56ac708b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bloque 2: Función de Extracción de Características\n",
    "def extract_features(file_path, n_mfcc=40):\n",
    "    \"\"\"Carga un archivo de audio (path) y extrae la media de 40 MFCCs.\"\"\"\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path, res_type='kaiser_fast') \n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "        features_vector = np.mean(mfccs.T, axis=0)\n",
    "    except Exception as e:\n",
    "        print(f\"Error cargando {file_path}: {e}\")\n",
    "        return None\n",
    "    return features_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f3c54f",
   "metadata": {},
   "source": [
    "# Bloque 3: Carga del Modelo\n",
    "\n",
    "- Propósito: Cargar en memoria el modelo .joblib que creamos en el notebook 1.\n",
    "'joblib.load()' lee el archivo y lo convierte de nuevo en un objeto de Python\n",
    "(nuestro clasificador 'model') que está listo para hacer predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "03bb5daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando modelo desde: clasificador_vehiculos.joblib\n",
      "¡Modelo cargado exitosamente!\n"
     ]
    }
   ],
   "source": [
    "# Bloque 3: Carga del Modelo\n",
    "print(f\"Cargando modelo desde: {MODELO_PATH}\")\n",
    "try:\n",
    "    model = joblib.load(MODELO_PATH)\n",
    "    print(\"¡Modelo cargado exitosamente!\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: No se encontró el archivo '{MODELO_PATH}'.\")\n",
    "    print(\"Asegúrate de ejecutar el Notebook '01_Entrenamiento_Modelo.ipynb' primero.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04f6714",
   "metadata": {},
   "source": [
    "# Bloque 4: Clasificación del Audio\n",
    "\n",
    "- Propósito: Usar el modelo\n",
    "\n",
    "1) Verifica si el archivo de audio existe.\n",
    "2) Llama a la función 'extract_features' (del Bloque 2) para convertir el audio en un vector.\n",
    "3) Usa 'model.predict()' para obtener la predicción (que será 0, 1 o 2).\n",
    "4) Usa 'CLASES_MAP' (del Bloque 1) para traducir el número a \"pequeno\", \"mediano\" o \"grande\".\n",
    "5) Muestra el resultado final al usuario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "04e33996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analizando audio: audio_random.wav...\n",
      "\n",
      "===============================\n",
      "     ✅ RESULTADO ✅\n",
      "===============================\n",
      "El audio 'audio_random.wav' ha sido clasificado como:\n",
      " -> **GRANDE**\n",
      "===============================\n"
     ]
    }
   ],
   "source": [
    "# Bloque 4: Clasificación del Audio\n",
    "print(f\"\\nAnalizando audio: {AUDIO_PARA_CLASIFICAR}...\")\n",
    "\n",
    "# Verificar que el audio exista\n",
    "if not os.path.exists(AUDIO_PARA_CLASIFICAR):\n",
    "    print(f\"ERROR: No se encontró el archivo de audio '{AUDIO_PARA_CLASIFICAR}'.\")\n",
    "else:\n",
    "    # Extraer características del audio (usando la misma función)\n",
    "    features = extract_features(AUDIO_PARA_CLASIFICAR, n_mfcc=N_MFCC)\n",
    "    \n",
    "    if features is not None:\n",
    "        # Preparar el vector para el modelo\n",
    "        features_2d = features.reshape(1, -1)\n",
    "        \n",
    "        # Predecir\n",
    "        prediccion_num = model.predict(features_2d)\n",
    "        \n",
    "        # Obtener el resultado en texto\n",
    "        clase_predicha = CLASES_MAP[prediccion_num[0]]\n",
    "        \n",
    "        # Mostrar el resultado\n",
    "        print(\"\\n===============================\")\n",
    "        print(\"     ✅ RESULTADO ✅\")\n",
    "        print(\"===============================\")\n",
    "        print(f\"El audio '{AUDIO_PARA_CLASIFICAR}' ha sido clasificado como:\")\n",
    "        print(f\" -> **{clase_predicha.upper()}**\")\n",
    "        print(\"===============================\")\n",
    "    else:\n",
    "        print(\"No se pudieron extraer características del audio.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03081b5b",
   "metadata": {},
   "source": [
    "EXPLIACION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "536ffc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import joblib\n",
    "import os \n",
    "\n",
    "MODELO_PATH = \"clasificador_vehiculos.joblib\"\n",
    "AUDIO_PARA_CLASIFICAR = \"audio_random.wav\" \n",
    "\n",
    "CLASES_MAP = {0: \"pequeno\", 1: \"mediano\", 2: \"grande\"} \n",
    "N_MFCC = 40 \n",
    "\n",
    "\n",
    "SEGMENT_DUR_SEC = 0.5  # Duración de la ventana de análisis (ej: 1 segundo)\n",
    "OVERLAP_RATIO = 0.8    # Solapamiento entre ventanas (50%)\n",
    "MIN_EVENT_SEGMENTS = 5 # Mínimo de segmentos consecutivos para contar como evento único"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9102972",
   "metadata": {},
   "source": [
    "EXPLICACION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "add0c55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_path, n_mfcc=40):\n",
    "    try:\n",
    "        # Si file_path es una ruta (string), cargamos. \n",
    "        # Si ya es un array de audio (segmento), usamos lo que viene.\n",
    "        if isinstance(file_path, str):\n",
    "             y, sr = librosa.load(file_path, res_type='kaiser_fast')\n",
    "        else:\n",
    "             # Caso especial para cuando pasas el segmento directo en el conteo\n",
    "             y = file_path\n",
    "             sr = 22050 # Valor por defecto de librosa si no se tiene sr\n",
    "        \n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "        \n",
    "        # --- MEJORA AQUÍ ---\n",
    "        # Calculamos la media Y la desviación estándar\n",
    "        mfccs_mean = np.mean(mfccs.T, axis=0)\n",
    "        mfccs_std = np.std(mfccs.T, axis=0)\n",
    "        \n",
    "        # Concatenamos ambos para tener un vector de 80 números (40 media + 40 std)\n",
    "        features_vector = np.hstack([mfccs_mean, mfccs_std])\n",
    "        # -------------------\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "    return features_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a389a729",
   "metadata": {},
   "source": [
    "EXPLICACION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c2d1e8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analizando audio largo: audio_random.wav...\n",
      "\n",
      "===============================\n",
      "      RESULTADO FINAL DE CONTEO\n",
      "===============================\n",
      "Audio analizado: audio_random.wav (13.47 segundos)\n",
      "Total de segmentos procesados: 130\n",
      "Duración mínima de evento para conteo: 5 segmentos.\n",
      "---\n",
      "Vehículos tipo **PEQUENO**: 1 detectados\n",
      "Vehículos tipo **MEDIANO**: 5 detectados\n",
      "Vehículos tipo **GRANDE**: 1 detectados\n",
      "===============================\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nAnalizando audio largo: {AUDIO_PARA_CLASIFICAR}...\")\n",
    "\n",
    "# 1. Verificar y Cargar el Audio Completo\n",
    "if not os.path.exists(AUDIO_PARA_CLASIFICAR):\n",
    "    print(f\"ERROR: No se encontró el archivo de audio '{AUDIO_PARA_CLASIFICAR}'.\")\n",
    "else:\n",
    "    # Cargar el modelo (Asume que el Bloque 3 ya cargó 'model')\n",
    "    try:\n",
    "        model = joblib.load(MODELO_PATH)\n",
    "    except Exception as e:\n",
    "        print(f\"Error al cargar el modelo: {e}. Asegúrese de ejecutar el notebook de entrenamiento.\")\n",
    "        exit()\n",
    "\n",
    "    # Cargar el audio completo\n",
    "    y, sr = librosa.load(AUDIO_PARA_CLASIFICAR, res_type='kaiser_fast') \n",
    "    \n",
    "    # 2. Configurar y Ejecutar la Ventana Deslizante\n",
    "    segment_len = int(SEGMENT_DUR_SEC * sr)    # Longitud de la ventana en muestras\n",
    "    hop_len = int(segment_len * (1 - OVERLAP_RATIO)) # Paso para el solapamiento\n",
    "\n",
    "    features_list = []\n",
    "    \n",
    "    # Iterar y extraer características de cada segmento\n",
    "    for i in range(0, len(y) - segment_len, hop_len):\n",
    "        y_segment = y[i:i + segment_len]\n",
    "        # NOTA: Usamos la función adaptada para segmentos\n",
    "        features = extract_features_segment(y_segment, sr, n_mfcc=N_MFCC)\n",
    "        \n",
    "        if features is not None:\n",
    "            features_list.append(features)\n",
    "\n",
    "    if not features_list:\n",
    "        print(\"No se pudieron extraer segmentos del audio (el archivo es muy corto o hubo un error).\")\n",
    "    else:\n",
    "        # 3. Predecir todos los segmentos\n",
    "        X_segments = np.array(features_list)\n",
    "        predicciones = model.predict(X_segments) # Array largo de predicciones [0, 0, 1, 1, 1, ...]\n",
    "\n",
    "        # 4. Lógica de Conteo de Eventos Únicos (Agregación)\n",
    "        conteo_final = {clase: 0 for clase in CLASES_MAP.values()}\n",
    "        \n",
    "        event_class = -1\n",
    "        consecutive_count = 0\n",
    "        \n",
    "        for pred in predicciones:\n",
    "            if pred == event_class:\n",
    "                # El evento continúa\n",
    "                consecutive_count += 1\n",
    "            else:\n",
    "                # El evento terminó o es el inicio de uno nuevo\n",
    "                if event_class != -1 and consecutive_count >= MIN_EVENT_SEGMENTS:\n",
    "                    # El evento anterior fue válido y se cuenta\n",
    "                    clase_texto = CLASES_MAP[event_class]\n",
    "                    conteo_final[clase_texto] += 1\n",
    "                \n",
    "                # Reiniciar el conteo para la nueva clase\n",
    "                event_class = pred\n",
    "                consecutive_count = 1\n",
    "        \n",
    "        # Comprobar el último evento al salir del bucle\n",
    "        if event_class != -1 and consecutive_count >= MIN_EVENT_SEGMENTS:\n",
    "            clase_texto = CLASES_MAP[event_class]\n",
    "            conteo_final[clase_texto] += 1\n",
    "            \n",
    "        # 5. Mostrar el resultado\n",
    "        print(\"\\n===============================\")\n",
    "        print(\"      RESULTADO FINAL DE CONTEO\")\n",
    "        print(\"===============================\")\n",
    "        print(f\"Audio analizado: {AUDIO_PARA_CLASIFICAR} ({len(y)/sr:.2f} segundos)\")\n",
    "        print(f\"Total de segmentos procesados: {len(features_list)}\")\n",
    "        print(f\"Duración mínima de evento para conteo: {MIN_EVENT_SEGMENTS} segmentos.\")\n",
    "        print(\"---\")\n",
    "        \n",
    "        for clase, count in conteo_final.items():\n",
    "            print(f\"Vehículos tipo **{clase.upper()}**: {count} detectados\")\n",
    "            \n",
    "        print(\"===============================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f5634c",
   "metadata": {},
   "source": [
    "EXPLICACION"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acus220",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
