{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db8020c9",
   "metadata": {},
   "source": [
    "# Bloque 1: Importaciones y Configuración\n",
    "\n",
    "- Propósito: Cargar las librerías necesarias (numpy, librosa, joblib, os).\n",
    "También definimos las variables clave:\n",
    "1) MODELO_PATH: Dónde está guardado nuestro modelo entrenado.\n",
    "2) AUDIO_PARA_CLASIFICAR: El nombre del archivo de audio que queremos probar.\n",
    "3) CLASES_MAP: Un \"diccionario\" para traducir la predicción numérica (0, 1, 2) a texto.\n",
    "4) N_MFCC: El número de características que usamos (debe ser el mismo del entrenamiento)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b95a361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaciones\n",
    "import numpy as np\n",
    "import librosa\n",
    "import joblib\n",
    "import os \n",
    "MODELO_PATH = \"clasificador_vehiculos.joblib\"\n",
    "AUDIO_PARA_CLASIFICAR = \"audio_random.wav\" \n",
    "\n",
    "# Mapeo de las etiquetas numéricas a texto\n",
    "CLASES_MAP = {0: \"pequeno\", 1: \"mediano\", 2: \"grande\"} \n",
    "N_MFCC = 40 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c24bae",
   "metadata": {},
   "source": [
    "# Bloque 2: Función de Extracción de Características\n",
    "\n",
    "- Propósito: Definir la función que convierte un archivo de audio en números.\n",
    "Esta función DEBE ser una copia exacta de la que se usó en el notebook 1.\n",
    "Carga el audio, calcula los 40 MFCCs, y luego calcula la media de esos MFCCs\n",
    "para obtener un solo vector de características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "56ac708b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bloque 2: Función de Extracción de Características\n",
    "def extract_features(file_path, n_mfcc=40):\n",
    "    \"\"\"Carga un archivo de audio (path) y extrae la media de 40 MFCCs.\"\"\"\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path, res_type='kaiser_fast') \n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "        features_vector = np.mean(mfccs.T, axis=0)\n",
    "    except Exception as e:\n",
    "        print(f\"Error cargando {file_path}: {e}\")\n",
    "        return None\n",
    "    return features_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f3c54f",
   "metadata": {},
   "source": [
    "# Bloque 3: Carga del Modelo\n",
    "\n",
    "- Propósito: Cargar en memoria el modelo .joblib que creamos en el notebook 1.\n",
    "'joblib.load()' lee el archivo y lo convierte de nuevo en un objeto de Python\n",
    "(nuestro clasificador 'model') que está listo para hacer predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "03bb5daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando modelo desde: clasificador_vehiculos.joblib\n",
      "¡Modelo cargado exitosamente!\n"
     ]
    }
   ],
   "source": [
    "# Bloque 3: Carga del Modelo\n",
    "print(f\"Cargando modelo desde: {MODELO_PATH}\")\n",
    "try:\n",
    "    model = joblib.load(MODELO_PATH)\n",
    "    print(\"¡Modelo cargado exitosamente!\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: No se encontró el archivo '{MODELO_PATH}'.\")\n",
    "    print(\"Asegúrate de ejecutar el Notebook '01_Entrenamiento_Modelo.ipynb' primero.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04f6714",
   "metadata": {},
   "source": [
    "# Bloque 4: Clasificación del Audio\n",
    "\n",
    "- Propósito: Usar el modelo\n",
    "\n",
    "1) Verifica si el archivo de audio existe.\n",
    "2) Llama a la función 'extract_features' (del Bloque 2) para convertir el audio en un vector.\n",
    "3) Usa 'model.predict()' para obtener la predicción (que será 0, 1 o 2).\n",
    "4) Usa 'CLASES_MAP' (del Bloque 1) para traducir el número a \"pequeno\", \"mediano\" o \"grande\".\n",
    "5) Muestra el resultado final al usuario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "04e33996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analizando audio: audio_random.wav...\n",
      "\n",
      "===============================\n",
      "     ✅ RESULTADO ✅\n",
      "===============================\n",
      "El audio 'audio_random.wav' ha sido clasificado como:\n",
      " -> **GRANDE**\n",
      "===============================\n"
     ]
    }
   ],
   "source": [
    "# Bloque 4: Clasificación del Audio\n",
    "print(f\"\\nAnalizando audio: {AUDIO_PARA_CLASIFICAR}...\")\n",
    "\n",
    "# Verificar que el audio exista\n",
    "if not os.path.exists(AUDIO_PARA_CLASIFICAR):\n",
    "    print(f\"ERROR: No se encontró el archivo de audio '{AUDIO_PARA_CLASIFICAR}'.\")\n",
    "else:\n",
    "    # Extraer características del audio (usando la misma función)\n",
    "    features = extract_features(AUDIO_PARA_CLASIFICAR, n_mfcc=N_MFCC)\n",
    "    \n",
    "    if features is not None:\n",
    "        # Preparar el vector para el modelo\n",
    "        features_2d = features.reshape(1, -1)\n",
    "        \n",
    "        # Predecir\n",
    "        prediccion_num = model.predict(features_2d)\n",
    "        \n",
    "        # Obtener el resultado en texto\n",
    "        clase_predicha = CLASES_MAP[prediccion_num[0]]\n",
    "        \n",
    "        # Mostrar el resultado\n",
    "        print(\"\\n===============================\")\n",
    "        print(\"     ✅ RESULTADO ✅\")\n",
    "        print(\"===============================\")\n",
    "        print(f\"El audio '{AUDIO_PARA_CLASIFICAR}' ha sido clasificado como:\")\n",
    "        print(f\" -> **{clase_predicha.upper()}**\")\n",
    "        print(\"===============================\")\n",
    "    else:\n",
    "        print(\"No se pudieron extraer características del audio.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03081b5b",
   "metadata": {},
   "source": [
    "EXPLIACION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "536ffc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import joblib\n",
    "import os \n",
    "\n",
    "MODELO_PATH = \"clasificador_vehiculos.joblib\"\n",
    "AUDIO_PARA_CLASIFICAR = \"audio_random.wav\" \n",
    "\n",
    "CLASES_MAP = {0: \"pequeno\", 1: \"mediano\", 2: \"grande\"} \n",
    "N_MFCC = 40 \n",
    "\n",
    "\n",
    "SEGMENT_DUR_SEC = 0.5  # Duración de la ventana de análisis (ej: 1 segundo)\n",
    "OVERLAP_RATIO = 0.8    # Solapamiento entre ventanas (50%)\n",
    "MIN_EVENT_SEGMENTS = 5 # Mínimo de segmentos consecutivos para contar como evento único"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9102972",
   "metadata": {},
   "source": [
    "EXPLICACION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add0c55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bloque 2: Función de extracción de características (VERSIÓN MEJORADA 80 FEATURES)\n",
    "def extract_features(file_path, n_mfcc=40):\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path, res_type='kaiser_fast') \n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "        \n",
    "        # --- CAMBIO CLAVE: AHORA CALCULAMOS MEDIA Y DESVIACIÓN ---\n",
    "        mfccs_mean = np.mean(mfccs.T, axis=0)\n",
    "        mfccs_std = np.std(mfccs.T, axis=0)\n",
    "        \n",
    "        # Unimos todo en un vector de 80 (40 media + 40 std)\n",
    "        features_vector = np.hstack([mfccs_mean, mfccs_std])\n",
    "        # ---------------------------------------------------------\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error cargando {file_path}: {e}\")\n",
    "        return None\n",
    "    return features_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a389a729",
   "metadata": {},
   "source": [
    "EXPLICACION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9aaf8832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analizando audio largo: audio_random.wav...\n",
      "\n",
      "❌ ERROR DE DIMENSIONES: X has 80 features, but RandomForestClassifier is expecting 40 features as input.\n",
      "Tu modelo espera un número diferente de características.\n",
      "Solución: Revisa si estás usando 'mean' y 'std' en ambos notebooks.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 80 features, but RandomForestClassifier is expecting 40 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 44\u001b[0m\n\u001b[0;32m     41\u001b[0m X_segments \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(features_list)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 44\u001b[0m     predicciones_raw \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_segments\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ve:\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m❌ ERROR DE DIMENSIONES: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mve\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\criis\\miniconda3\\envs\\acus220\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:903\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    882\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    883\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[0;32m    885\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 903\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    905\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    906\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\criis\\miniconda3\\envs\\acus220\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:945\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    943\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    944\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[1;32m--> 945\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    947\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    948\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32mc:\\Users\\criis\\miniconda3\\envs\\acus220\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:637\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    635\u001b[0m     ensure_all_finite \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 637\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    638\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    639\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    640\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    641\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    644\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    645\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[0;32m    646\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\criis\\miniconda3\\envs\\acus220\\lib\\site-packages\\sklearn\\utils\\validation.py:2975\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2972\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m   2974\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m-> 2975\u001b[0m     \u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2977\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\criis\\miniconda3\\envs\\acus220\\lib\\site-packages\\sklearn\\utils\\validation.py:2839\u001b[0m, in \u001b[0;36m_check_n_features\u001b[1;34m(estimator, X, reset)\u001b[0m\n\u001b[0;32m   2836\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   2838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m-> 2839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2840\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2841\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2842\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 80 features, but RandomForestClassifier is expecting 40 features as input."
     ]
    }
   ],
   "source": [
    "from scipy.stats import mode\n",
    "import numpy as np\n",
    "import librosa\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "print(f\"\\nAnalizando audio largo: {AUDIO_PARA_CLASIFICAR}...\")\n",
    "\n",
    "# 1. Verificar existencia del archivo\n",
    "if not os.path.exists(AUDIO_PARA_CLASIFICAR):\n",
    "    print(f\"ERROR: No se encontró el archivo '{AUDIO_PARA_CLASIFICAR}'.\")\n",
    "else:\n",
    "    # Cargar modelo\n",
    "    try:\n",
    "        model = joblib.load(MODELO_PATH)\n",
    "    except Exception as e:\n",
    "        print(f\"Error cargando modelo: {e}\")\n",
    "        # Terminamos aquí si no hay modelo\n",
    "        raise \n",
    "\n",
    "    # Cargar audio\n",
    "    y, sr = librosa.load(AUDIO_PARA_CLASIFICAR, res_type='kaiser_fast')\n",
    "    \n",
    "    # 2. Configurar Ventana\n",
    "    segment_len = int(SEGMENT_DUR_SEC * sr)\n",
    "    hop_len = int(segment_len * (1 - OVERLAP_RATIO))\n",
    "\n",
    "    features_list = []\n",
    "    \n",
    "    # Extraer características\n",
    "    for i in range(0, len(y) - segment_len, hop_len):\n",
    "        y_segment = y[i:i + segment_len]\n",
    "        features = extract_features_segment(y_segment, sr, n_mfcc=N_MFCC)\n",
    "        if features is not None:\n",
    "            features_list.append(features)\n",
    "\n",
    "    if not features_list:\n",
    "        print(\"Error: No se extrajeron segmentos.\")\n",
    "    else:\n",
    "        # 3. Predecir\n",
    "        X_segments = np.array(features_list)\n",
    "        \n",
    "        try:\n",
    "            predicciones_raw = model.predict(X_segments)\n",
    "        except ValueError as ve:\n",
    "            print(f\"\\n❌ ERROR DE DIMENSIONES: {ve}\")\n",
    "            print(\"Tu modelo espera un número diferente de características.\")\n",
    "            print(\"Solución: Revisa si estás usando 'mean' y 'std' en ambos notebooks.\")\n",
    "            raise\n",
    "\n",
    "        # --- LÓGICA DE SUAVIZADO (MEJORA CLAVE) ---\n",
    "        predicciones_suavizadas = []\n",
    "        # Ventana de suavizado (debe ser impar, ej: 3 o 5)\n",
    "        ventana_suave = 5 \n",
    "        \n",
    "        for i in range(len(predicciones_raw)):\n",
    "            inicio = max(0, i - ventana_suave // 2)\n",
    "            fin = min(len(predicciones_raw), i + ventana_suave // 2 + 1)\n",
    "            fragmento = predicciones_raw[inicio:fin]\n",
    "            \n",
    "            # Calcular la moda (el valor más común en los vecinos)\n",
    "            moda_res = mode(fragmento, keepdims=True)\n",
    "            predicciones_suavizadas.append(moda_res.mode[0])\n",
    "            \n",
    "        predicciones = predicciones_suavizadas\n",
    "        # -------------------------------------------\n",
    "\n",
    "        # 4. Conteo de Eventos\n",
    "        conteo_final = {clase: 0 for clase in CLASES_MAP.values()}\n",
    "        event_class = -1\n",
    "        consecutive_count = 0\n",
    "        \n",
    "        for pred in predicciones:\n",
    "            if pred == event_class:\n",
    "                consecutive_count += 1\n",
    "            else:\n",
    "                if event_class != -1 and consecutive_count >= MIN_EVENT_SEGMENTS:\n",
    "                    clase_texto = CLASES_MAP[event_class]\n",
    "                    conteo_final[clase_texto] += 1\n",
    "                \n",
    "                event_class = pred\n",
    "                consecutive_count = 1\n",
    "        \n",
    "        # Último evento\n",
    "        if event_class != -1 and consecutive_count >= MIN_EVENT_SEGMENTS:\n",
    "            clase_texto = CLASES_MAP[event_class]\n",
    "            conteo_final[clase_texto] += 1\n",
    "            \n",
    "        # 5. Mostrar Resultados\n",
    "        print(\"\\n===============================\")\n",
    "        print(\"      RESULTADO FINAL DE CONTEO\")\n",
    "        print(\"===============================\")\n",
    "        print(f\"Audio: {AUDIO_PARA_CLASIFICAR} ({len(y)/sr:.2f} s)\")\n",
    "        print(f\"Segmentos: {len(features_list)}\")\n",
    "        print(f\"Config: {SEGMENT_DUR_SEC}s ventana / {OVERLAP_RATIO*100}% overlap\")\n",
    "        print(\"---\")\n",
    "        for clase, count in conteo_final.items():\n",
    "            print(f\"Vehículos tipo **{clase.upper()}**: {count}\")\n",
    "        print(\"===============================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f5634c",
   "metadata": {},
   "source": [
    "EXPLICACION"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acus220",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
